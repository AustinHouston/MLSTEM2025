{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74f58a7b-f09f-4d8c-9ec1-4e34644eb46e",
   "metadata": {},
   "source": [
    "# ML in Electron Microscopy School\n",
    "\n",
    "## Digital Twin Microscopy\n",
    "\n",
    "### Tutorial by Rama Vasudevan, CNMS ORNL\n",
    "\n",
    "#### Why Digital Twin Microscopes? \n",
    "\n",
    "Digital Twin microscopes are useful for trialing machine learning algorithms in a safe, cheap, and effective environment without the need for the physical instrument to be present. The idea is that by ensuring that the algorithm is functional within the digital twin, it will be functional when it comes to using the algorithm on the real instrument. \n",
    "\n",
    "Since insturment time is often expensive, and failures can be catastrophic, it is essential to conduct proper testing. In software environments, this is called unit testing; digital twins enable unit testing for active learning - ML in STEM scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5286bdae-d45d-493e-b2c7-0a008b5982a4",
   "metadata": {},
   "source": [
    "# What is the difference between a STEM simulation and a digital twin microscope?\n",
    "\n",
    "Discussion point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4151519d-f391-4319-aca2-120042441c1e",
   "metadata": {},
   "source": [
    "# What kind of data does a Digital Twin of a microscope produce?\n",
    "\n",
    "DT Microscopes can, depending on how they are written, produce both pre-acquired (real) data as well as generate simulated data. Where possible, it is usually best to stick with real datasets, given the limitations of simulation, although simulation has the advantage of known ground truth structure, making it advantageous for benchmarking certain ML tasks (such as image segmentation, and so on). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33898053-87bf-458d-b4f0-14a1725cf57a",
   "metadata": {},
   "source": [
    "# Play with our digital Twin microscope\n",
    "\n",
    "<b>Link to Colab Notebook 1:</b> <a href = \"https://colab.research.google.com/github/pycroscopy/DTMicroscope/blob/main/notebooks/STEM/1_stem_eels_clustering_COLAB-Hackathon.ipynb#scrollTo=egfQZ_fU1zKt\"> STEM EELS Clustering </a>\n",
    "\n",
    "In the above notebook, we will capture an overview image scan, and then capture EELS spectra from different locations. Play with this notebook and see how it works. Then, see if you can generate a dataset which maps the local image patch to the local EELs spectra.\n",
    "\n",
    "\n",
    "<b>Link to Colab Notebook 2:</b> <a href = \"https://github.com/ramav87/MLSTEM2024/blob/main/notebooks/STEM/2_active_learning_dkl_COLAB-Hackathon_updated.ipynb\"> Deep Kernel Active Learning STEM Example </a>\n",
    "\n",
    "This example shows how deep kernel learning can be used for this adaptive sampling/optimization of some chosen spectral property in STEM. How do the results change if you change the sclarizer in this example?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78f5b25-db5b-4c28-98a7-03a3c8ac320d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
